{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mPZ4suK5OgJ"
      },
      "source": [
        "# Lab 3: Plasticity and learning\n",
        "\n",
        "In this lab, we will from static circuit to dynamics circuit where the connectivity will change following plasticity rules in un-supervised way or reward-dependent way. \n",
        "\n",
        "(Code by Lihao Guo, Questions by Arvind Kumar 2022. The tutorial is inspired by the Neuronal Dynamics book from Wulfram Gerstner, Werner M. Kistler, Richard Naud and Liam Paninski. https://neuronaldynamics.epfl.ch/online/index.html. Last part is from Nengo.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT9SPEg55IoV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to initialize lab environment.\n",
        "debug = 'google.colab' not in str(get_ipython())\n",
        "if not debug:\n",
        "    import os, sys\n",
        "\n",
        "    # clone respository\n",
        "    user = \"michaelglh\"\n",
        "    repo = \"STG\"\n",
        "    if os.path.isdir(repo):\n",
        "        !rm -rf {repo}\n",
        "    !git clone https://github.com/{user}/{repo}.git\n",
        "\n",
        "    # add path to system\n",
        "    src_dir = \"\"\n",
        "    path = f\"{repo}/{src_dir}\"\n",
        "    if not path in sys.path:\n",
        "        sys.path.insert(1, path)\n",
        "\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "    !pip install ipympl==0.8.0 --quiet\n",
        "    !pip install nengo nengo-gui nengo_extras --quiet\n",
        "\n",
        "    import matplotlib.backends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "weDD9htnp4Oj"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to download necessary files.\n",
        "from lib.neuron import LIF\n",
        "from lib.input import Poisson_generator, Gaussian_generator, Current_injector\n",
        "from lib.conn import Simulator\n",
        "from lib.helper import plot_volt_trace, pair_volt_trace\n",
        "    \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats                      \n",
        "import ipywidgets as widgets            # interactive display\n",
        "my_layout = widgets.Layout()\n",
        "\n",
        "import nengo\n",
        "from nengo_extras.data import load_mnist, one_hot_from_labels\n",
        "from nengo_extras.matplotlib import tile\n",
        "from nengo_extras.vision import Gabor, Mask\n",
        "\n",
        "# setting for figures\n",
        "fig_w, fig_h = 8, 6\n",
        "my_fontsize = 18\n",
        "my_params = {'axes.labelsize': my_fontsize,\n",
        "          'axes.titlesize': my_fontsize,\n",
        "          'figure.figsize': (fig_w, fig_h),\n",
        "          'font.size': my_fontsize,\n",
        "          'legend.fontsize': my_fontsize-4,\n",
        "          'lines.markersize': 8.,\n",
        "          'lines.linewidth': 2.,\n",
        "          'xtick.labelsize': my_fontsize-2,\n",
        "          'ytick.labelsize': my_fontsize-2}\n",
        "\n",
        "plt.rcParams.update(my_params)\n",
        "\n",
        "# Auto Reloading\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaQp3jdpnejR"
      },
      "source": [
        "### Different types of synaptic plasticities\n",
        "* Two-factor plasticity\n",
        "* Spike-timeing-dependent long-term plasticity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yZW28-2FOBG5"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to start hebbain plasticity simulation { vertical-output: true }\n",
        "T, dt = 1e3, 0.1        # simulation period(ms), step size(ms)\n",
        "N = 2                  # number of neurons\n",
        "\n",
        "# neuron types\n",
        "tonic_neuron = {'tau_m':20., 'a':0., 'tau_w':30., 'b':3., 'V_reset':-55.}\n",
        "adapting_neuron = {'tau_m':20., 'a':0., 'tau_w':100., 'b':0.5, 'V_reset':-55.}\n",
        "initburst_neuron = {'tau_m':10., 'a':0., 'tau_w':100., 'b':1., 'V_reset':-50.}\n",
        "bursting_neuron = {'tau_m':5., 'a':0., 'tau_w':100., 'b':1., 'V_reset':-46.}\n",
        "irregular_neuron = {'tau_m':10., 'a':-0.01, 'tau_w':50., 'b':1.2, 'V_reset':-46.}\n",
        "transient_neuron = {'tau_m':5., 'a':0.05, 'tau_w':100., 'b':0.7, 'V_reset':-60.}\n",
        "delayed_neuron = {'tau_m':5., 'a':-0.1, 'tau_w':100., 'b':1., 'V_reset':-60.}\n",
        "rebound_neuron = {'tau_m':5., 'a':0.2, 'tau_w':150., 'b':0.1, 'V_reset':-54.}\n",
        "\n",
        "neuron_params = {'tonic_neuron': tonic_neuron, 'adapting_neuron': adapting_neuron, \n",
        "                 'initburst_neuron': initburst_neuron, 'bursting_neuron': bursting_neuron, \n",
        "                 'irregular_neuron': irregular_neuron, 'transient_neuron': transient_neuron, \n",
        "                 'delayed_neuron': delayed_neuron, 'rebound_neuron': rebound_neuron}\n",
        "    \n",
        "# input types\n",
        "Itypes = ['Gaussian', 'Poisson']\n",
        "\n",
        "# connection types\n",
        "Ctypes = ['Static', 'Hebb', 'STDP']\n",
        "\n",
        "# updating parameters\n",
        "def update_pls(c_ts='Static', J_ts=1.0, rt=50., rs=50., Itype='Icur'):\n",
        "    # simualtor\n",
        "    h = Simulator(dt=dt)\n",
        "\n",
        "    # network of neurons\n",
        "    nrns = [LIF(sim=h) for _ in range(N)]\n",
        "    for nrn in nrns:\n",
        "        nrn.update(tonic_neuron)\n",
        "\n",
        "    # background noise\n",
        "    if Itype == 'Gaussian':\n",
        "        noises = [Gaussian_generator(sim=h, mean=r, std=r, start=int(T/dt*0.25), end=int(T/dt*0.75)) for r in [rt, rs]]\n",
        "    elif Itype == 'Poisson':\n",
        "        noises = [Poisson_generator(sim=h, rate=r*3, start=int(T/dt*0.25), end=int(T/dt*0.75)) for r in [rt, rs]]\n",
        "    else:\n",
        "        print('Invalid input')\n",
        "    for noise, nrn in zip(noises, nrns):\n",
        "        nrn.connect(noise, {'ctype':'Static', 'weight':1e0, 'delay':5})      \n",
        "\n",
        "    # recurrent connections\n",
        "    tps = [['Static' for _ in range(N)] for _ in range(N)]\n",
        "    tps[0][1] = c_ts\n",
        "    con = np.array([[0., J_ts],\n",
        "                    [0., 0.]])\n",
        "    dly = np.random.uniform(2., 5., (N,N))\n",
        "    synspecs = [[{} for _ in range(N)] for _ in range(N)]\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            synspecs[i][j] = {'ctype':tps[i][j], 'weight':con[i,j], 'delay':dly[i,j]}\n",
        "    cons = h.connect(nrns, nrns, synspecs)\n",
        "\n",
        "    # simulation\n",
        "    h.run(T)\n",
        "\n",
        "    # visualize\n",
        "    plt.clf()\n",
        "    cs = ['b', 'r']\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('raster')\n",
        "    for nrn, c, l in zip(nrns, cs, range(N)):\n",
        "        plt.eventplot(nrn.spikes['times'], lineoffsets=2*l, colors=c, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "    plt.xlabel('Time(ms)')\n",
        "    plt.yticks(list(np.arange(N)*2), ['T', 'S'])\n",
        "    plt.xlim([0., T])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(np.arange(0., T, dt), cons[0][1].weights, c='purple')\n",
        "    for nrn, c in zip(nrns, cs):\n",
        "        plt.eventplot(nrn.spikes['times'], lineoffsets=0, linelengths=0.5, colors=c)\n",
        "    plt.xlabel('Time(ms)')\n",
        "    plt.ylabel('Relative amp')\n",
        "    plt.tight_layout()\n",
        "\n",
        "try:\n",
        "    plt.close(fig_pls)\n",
        "except:\n",
        "    ...\n",
        "fig_pls, axes = plt.subplots(1,2,figsize=(10,5))\n",
        "widgets.interact(update_pls, c_ts=Ctypes, J_ts=(0.01, 2., 0.01), rt=(0., 100., 10.), rs=(0., 100., 10.), Itype=Itypes);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ33p5-JOBG6"
      },
      "source": [
        "### Learning\n",
        "\n",
        "* Unsupervised competitive learning (rate model)\n",
        "* Encoding/decoding with receptive field\n",
        "\n",
        "<img src=\"https://github.com/michaelglh/STG/blob/master/figs/encoding.png?raw=1\" alt=\"Encoding network\" width=\"1200\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W1PHVnstOBG7"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to manipulate tuning curve { vertical-output: true }\n",
        "T, dt = 3e2, 0.1        # simulation period(ms), step size(ms)\n",
        "N = 11                  # number of neurons\n",
        "\n",
        "# inputs\n",
        "ms, std, xs = np.linspace(0., 1., 101), 0.1, np.linspace(0.05-1e-5, 0.95-1e-5, N-1)\n",
        "rins = [np.array([max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x]))  for x in xs]) for mean in ms]\n",
        "\n",
        "# weights\n",
        "grid = widgets.GridspecLayout(2, N)\n",
        "wsize = '200px'\n",
        "for i, label in enumerate(['center'] + ['J_o%d'%i for i in np.arange(1, N)]):\n",
        "    grid[0, i] = widgets.Text(value=label, disabled=True, layout=widgets.Layout(width=wsize))\n",
        "for i in np.arange(1, N):\n",
        "    grid[1, i] = widgets.FloatSlider(value=0.2, min=0.0, max=0.4, step=0.01, layout=widgets.Layout(width=wsize))\n",
        "grid[1, 0] = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01, layout=widgets.Layout(width=wsize))\n",
        "\n",
        "con_bars = {}\n",
        "con_bars['mean'] = grid[1, 0]\n",
        "for i in np.arange(1, N):\n",
        "    con_bars['J_o%d'%i] = grid[1, i]\n",
        "\n",
        "# updating parameters\n",
        "def update_tune(**con_dict):\n",
        "    # simualtor\n",
        "    h = Simulator(dt=dt)\n",
        "\n",
        "    # network of neurons\n",
        "    nrns = [LIF(sim=h) for _ in range(N)]\n",
        "    for nrn in nrns:\n",
        "        nrn.update(tonic_neuron)\n",
        "\n",
        "    # input and weights\n",
        "    cons = np.array(list(con_dict.values()), dtype=float)\n",
        "    mean, ws = cons[0], cons[1:] \n",
        "\n",
        "    # background noise\n",
        "    rdist = [max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs]\n",
        "    rs = np.array([0.5] + rdist)*1e2\n",
        "    noises = [Poisson_generator(sim=h, rate=r*3, start=0, end=int(T/dt)) for r in rs]\n",
        "    for noise, nrn in zip(noises, nrns):\n",
        "        nrn.connect(noise, {'ctype':'Static', 'weight':1e0, 'delay':5})      \n",
        "\n",
        "    # recurrent connections\n",
        "    tps = [['Static' for _ in range(N)] for _ in range(N)]\n",
        "    con = np.zeros((N,N))\n",
        "    con[0, 1:] = ws * 5\n",
        "    dly = np.random.uniform(2., 5., (N,N))\n",
        "    synspecs = [[{} for _ in range(N)] for _ in range(N)]\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            synspecs[i][j] = {'ctype':tps[i][j], 'weight':con[i,j], 'delay':dly[i,j]}\n",
        "    h.connect(nrns, nrns, synspecs)\n",
        "\n",
        "    # simulation\n",
        "    h.run(T)\n",
        "\n",
        "    # save weight\n",
        "    ys = np.array([np.dot(ws, rin) for rin in rins])\n",
        "\n",
        "    # visualize\n",
        "    plt.clf()\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('raster')\n",
        "    for nrn, l in zip(nrns, range(N)):\n",
        "        if l == 0:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='r', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "        else:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='b', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "    plt.xlabel('time(ms)')\n",
        "    plt.yticks(list(np.arange(N)), ['out'] + list(np.arange(1, N)))\n",
        "    plt.ylabel('nrn idx')\n",
        "    plt.xlim([0., T])\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('tuning curve')\n",
        "    plt.plot(ms, ys)\n",
        "    plt.xlabel('mean')\n",
        "    plt.ylabel('response level')\n",
        "    plt.ylim([0, 3])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "try:\n",
        "    plt.close(fig_tune)\n",
        "except:\n",
        "    ...\n",
        "fig_tune, axes = plt.subplots(1,2,figsize=(10,5))\n",
        "widget_tune = widgets.interactive_output(update_tune, con_bars);\n",
        "display(grid, widget_tune);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GGAyIyqWOBG7"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to start competitive learning { vertical-output: true }\n",
        "T, dt = 3e2, 0.1        # simulation period(ms), step size(ms)\n",
        "N = 11                  # number of neurons\n",
        "\n",
        "# output neurons\n",
        "out_labels = ['a', 'b', 'c']\n",
        "M = len(out_labels)                   # number of cells\n",
        "\n",
        "# inputs\n",
        "std_low, std_high = 0.1, 0.5\n",
        "ms, ss, xs = np.linspace(0., 1., 11), np.linspace(std_low, std_high, 11), np.linspace(0.05-1e-5, 0.95-1e-5, N-1)\n",
        "rins = np.array([[[max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs] for std in ss] for mean in ms]) \n",
        "\n",
        "# weights\n",
        "ws = np.ones((M, N-1)) * 0.25\n",
        "\n",
        "# outputs\n",
        "ys = np.zeros((M, len(ms), len(ss)))\n",
        "\n",
        "# updating parameters\n",
        "def update_comp(mean=0.5, std=0.1,  outIdx='a', plasticity=False, Itype='Icur'):\n",
        "    nIdx = out_labels.index(outIdx)\n",
        "    # simualtor\n",
        "    h = Simulator(dt=dt)\n",
        "\n",
        "    # network of neurons\n",
        "    nrns = [LIF(sim=h) for _ in range(N)]\n",
        "    for nrn in nrns:\n",
        "        nrn.update(tonic_neuron)\n",
        "\n",
        "    # background noise\n",
        "    rdist = [max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs]\n",
        "    rs = np.array([1.0] + rdist)*5e2/np.sum(rdist)\n",
        "    if Itype == 'Gaussian':\n",
        "        noises = [Gaussian_generator(sim=h, mean=r, std=r, start=0, end=int(T/dt)) for r in rs]\n",
        "    elif Itype == 'Poisson':\n",
        "        noises = [Poisson_generator(sim=h, rate=r*3, start=0, end=int(T/dt)) for r in rs]\n",
        "    else:\n",
        "        print('Invalid input')\n",
        "    for noise, nrn in zip(noises, nrns):\n",
        "        nrn.connect(noise, {'ctype':'Static', 'weight':1e0, 'delay':5})      \n",
        "\n",
        "    # recurrent connections\n",
        "    tps = [['Static' for _ in range(N)] for _ in range(N)]\n",
        "    if plasticity:\n",
        "        for i in np.arange(1, N):\n",
        "            tps[0][i] = 'Comp'\n",
        "    con = np.zeros((N,N))\n",
        "    global ws\n",
        "    global ys\n",
        "    con[0, 1:] = ws[nIdx]\n",
        "    dly = np.random.uniform(2., 5., (N,N))\n",
        "    synspecs = [[{} for _ in range(N)] for _ in range(N)]\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            synspecs[i][j] = {'ctype':tps[i][j], 'weight':con[i,j], 'delay':dly[i,j]}\n",
        "    cons = h.connect(nrns, nrns, synspecs)\n",
        "\n",
        "    # simulation\n",
        "    h.run(T)\n",
        "\n",
        "    # save weight\n",
        "    if plasticity:\n",
        "        ws[nIdx] = np.array([cons[0][i].weights[-1] for i in np.arange(1, N)])\n",
        "        for i in range(len(ms)):\n",
        "            for j in range(len(ss)):\n",
        "                ys[nIdx, i, j] = np.dot(ws[nIdx], rins[i,j])\n",
        "    responses = np.array([np.dot(ws[i], rdist) for i in range(M)])\n",
        "    \n",
        "\n",
        "    # visualize\n",
        "    plt.clf()\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.title('raster')\n",
        "    for nrn, l in zip(nrns, range(N)):\n",
        "        if l == 0:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='r', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "        else:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='b', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "    plt.xlabel('time(ms)')\n",
        "    plt.yticks(list(np.arange(N)), [outIdx] + list(np.arange(1, N)))\n",
        "    plt.ylabel('nrn idx')\n",
        "    plt.xlim([0., T])\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.title('synaptic weights')\n",
        "    if plasticity:\n",
        "        weights = np.array([cons[0][i].weights for i in np.arange(1, N)])\n",
        "        plt.imshow(weights[:, np.arange(0, int(T/dt), 100)], extent=[0, T, 1, 10], origin='lower', aspect=30)\n",
        "    else:\n",
        "        plt.imshow(np.tile(ws[nIdx], (int(T/dt/100), 1)).T, extent=[0, T, 1, 10], origin='lower', aspect=30)\n",
        "    plt.xlabel('time(ms)')\n",
        "    plt.ylabel('syn Idx')\n",
        "    plt.colorbar()\n",
        "\n",
        "    plt.subplot(2,2,4)\n",
        "    plt.title('tuning curve')\n",
        "    plt.imshow(ys[nIdx], extent=[std_low, std_high, 0., 1.0], origin='lower', aspect=std_high - std_low)\n",
        "    plt.xlabel('std')\n",
        "    plt.ylabel('mean')\n",
        "    plt.colorbar()\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    plt.title('output responses')\n",
        "    plt.scatter(range(M), responses)\n",
        "    plt.xlabel('cell idx')\n",
        "    plt.xticks(list(np.arange(M)), out_labels)\n",
        "    plt.ylabel('response level')\n",
        "    plt.ylim([0, 5])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "try:\n",
        "    plt.close(fig_comp)\n",
        "except:\n",
        "    ...\n",
        "fig_comp, axes = plt.subplots(2,2,figsize=(10,10))\n",
        "widgets.interact(update_comp, mean=(0., 1.0, 0.01), std=(std_low, std_high, 0.01), outIdx=out_labels, plasticity=[True, False], Itype=Itypes);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ea3jW_l6OBG8"
      },
      "outputs": [],
      "source": [
        "#@title Run the following to start visual encoding/decoding\n",
        "rng = np.random.RandomState(9)\n",
        "\n",
        "# --- load the data\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# pylint: disable=unbalanced-tuple-unpacking\n",
        "if not debug:\n",
        "  mnist_path = \"STG/data/mnist.pkl.gz\"\n",
        "else:\n",
        "  mnist_path = \"./data/mnist.pkl.gz\"\n",
        "(X_train, y_train), (X_test, y_test) = load_mnist(mnist_path)\n",
        "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
        "X_test = 2 * X_test - 1  # normalize to -1 to 1\n",
        "\n",
        "T_train = one_hot_from_labels(y_train, classes=10)\n",
        "\n",
        "# --- set up network parameters\n",
        "n_vis = X_train.shape[1]\n",
        "n_out = T_train.shape[1]\n",
        "\n",
        "# number of hidden units\n",
        "# More means better performance but longer training time.\n",
        "n_hid = 1000\n",
        "\n",
        "ens_params = dict(\n",
        "    eval_points=X_train,\n",
        "    neuron_type=nengo.LIFRate(),\n",
        "    intercepts=nengo.dists.Choice([0.1]),\n",
        "    max_rates=nengo.dists.Choice([100]),\n",
        ")\n",
        "\n",
        "solver = nengo.solvers.LstsqL2(reg=0.01)\n",
        "\n",
        "with nengo.Network(seed=3) as model:\n",
        "    a = nengo.Ensemble(n_hid, n_vis, **ens_params)\n",
        "    v = nengo.Node(size_in=n_out)\n",
        "    conn = nengo.Connection(\n",
        "        a, v, synapse=None, eval_points=X_train, function=T_train, solver=solver\n",
        "    )\n",
        "\n",
        "\n",
        "def get_outs(simulator, images):\n",
        "    # encode the images to get the ensemble activations\n",
        "    _, acts = nengo.utils.ensemble.tuning_curves(a, simulator, inputs=images)\n",
        "\n",
        "    # decode the ensemble activities using the connection's decoders\n",
        "    return np.dot(acts, simulator.data[conn].weights.T)\n",
        "\n",
        "\n",
        "def get_error(simulator, images, labels):\n",
        "    # the classification for each example is index of\n",
        "    # the output dimension with the highest value\n",
        "    return np.argmax(get_outs(simulator, images), axis=1) != labels\n",
        "\n",
        "\n",
        "def print_error(simulator):\n",
        "    train_error = 100 * get_error(simulator, X_train, y_train).mean()\n",
        "    test_error = 100 * get_error(simulator, X_test, y_test).mean()\n",
        "    print(\"Train/test error: %0.2f%%, %0.2f%%\" % (train_error, test_error))\n",
        "\n",
        "# updating parameters\n",
        "encoder_labels = ['dense_normal', 'sparse_normal', 'dense_gabor', 'sparse_gabor']\n",
        "\n",
        "def update_vis(encoder='dense_normal'):\n",
        "    if encoder_labels.index(encoder) == 0:\n",
        "        encoders = rng.normal(size=(n_hid, 28 * 28))\n",
        "    elif encoder_labels.index(encoder) == 1:\n",
        "        encoders = rng.normal(size=(n_hid, 11, 11))\n",
        "        encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
        "    elif encoder_labels.index(encoder) == 2:\n",
        "        encoders = Gabor().generate(n_hid, (28, 28), rng=rng).reshape((n_hid, -1))\n",
        "    elif encoder_labels.index(encoder) == 3:\n",
        "        encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
        "        encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
        "    a.encoders = encoders\n",
        "\n",
        "    plt.clf()\n",
        "    tile(encoders.reshape((-1, 28, 28)), rows=4, cols=6, grid=True)\n",
        "\n",
        "    with nengo.Simulator(model) as sim:\n",
        "        print_error(sim)\n",
        "\n",
        "try:\n",
        "    plt.close(fig_vis)\n",
        "except:\n",
        "    ...\n",
        "fig_vis = plt.figure()\n",
        "widgets.interact(update_vis, encoder=encoder_labels);"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pls_colab.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9914d6bfacb954328c3ffb911a6400e44a72a30de8da69be678e590a88116170"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}